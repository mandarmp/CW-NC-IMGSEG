{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mandar_model_try_UNET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2guthgOz-Ssm"
      },
      "source": [
        "# Coursework for Cardiac MR Image Segmentation (2021-2022)\n",
        "\n",
        "After you have gone through the coursework description, this tutorial is designed to further helps you understand the problem and therefore enable you to propose a good solution for this coursework. You will learn:\n",
        "\n",
        "* how to load and save images with OpenCV\n",
        "* how to train a segmentation model with Pytorch\n",
        "* how to evaluate the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsnVbP35-Sso"
      },
      "source": [
        "## 1. Load, show, and save images with OpenCV\n",
        "\n",
        "OpenCV is an open-source computer vision library which helps us to manipulate image data. In this section, we will cover:\n",
        "* Loading an image from file with imread()\n",
        "* Displaying the image with matplotlib plt.imshow()\n",
        "* Saving an image with imwrite()\n",
        "\n",
        "For a more comprehensive study of OpenCV, we encourage you to check the official [OpenCV documentation](https://docs.opencv.org/master/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB-PYVl-SOkm",
        "outputId": "bde44ad9-837d-410f-8b5e-68bf0c960359"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwKOtbVsc8C8",
        "outputId": "34cb9ddc-a64c-4b2b-ca82-422d3efe5546"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device  :',device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device  : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ZvSiY3qW_U"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img, cmap=cmap)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(mask, cmap=cmap)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN5WJ_XG-Sso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "48cdb418-ad73-44e1-baf0-ff1009c17efc"
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2 #import OpenCV\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/data/train/'\n",
        "image = cv2.imread(os.path.join(data_dir,'image','cmr1.png'), cv2.IMREAD_UNCHANGED)\n",
        "mask = cv2.imread(os.path.join(data_dir,'mask','cmr1_mask.png'), cv2.IMREAD_UNCHANGED)\n",
        "show_image_mask(image, mask, cmap='gray')\n",
        "plt.pause(1)\n",
        "cv2.imwrite(os.path.join('./','cmr1.png'), mask*85)\n",
        "print(image.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UDvsGZnYfHS"
      },
      "source": [
        "Note: You will no doubt notice that the mask images appear to be completely black with no sign of any segmentations. This is because the max intensity of pixels in an 8-bit png image is 255 and your image viewer software only sees 255 as white. For those values close to zero, you will only see dark values. This is the case for our masks as the background, the right ventricle, the myocardium, and the left ventricle in each image are 0, 1, 2, and 3, respectively. All of which are close to zero. If we multiply the original mask by 85 and save the result to the directory where this code is, we can see the heart indeed shows up. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hULAX3WH-Sss"
      },
      "source": [
        "## 2 Define a segmentation model with Pytorch\n",
        "\n",
        "In this section, we expect you to learn how to:\n",
        "* Define a Segmentation Model\n",
        "* Define a DataLoader that inputs images to the Model\n",
        "* Define training parameters and train the model\n",
        "* Test the trained model with a new input image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrKFgoZvUbeg"
      },
      "source": [
        "### 2.1 Define a DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9s43MqqW_U"
      },
      "source": [
        "Below we provide you with a dataloader to use in your assigment. You will only need to focus on the development of your model and loss function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYrD95T8qz8T"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "path = '/content/drive/MyDrive/data/train'\n",
        "\n",
        "\n",
        "class TrainDataset(data.Dataset):\n",
        "    def __init__(self, root=path):\n",
        "        super(TrainDataset, self).__init__()\n",
        "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "        #print(self.img_files)\n",
        "        self.mask_files = []\n",
        "        #print(self.img_files)\n",
        "        for img_path in self.img_files:\n",
        "            basename = os.path.basename(img_path)\n",
        "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
        "            \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            mask_path = self.mask_files[index]\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()    #tensor vlaues for data( image) and label( mask) is returned.\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "class TestDataset(data.Dataset):\n",
        "    def __init__(self, root=''):\n",
        "        super(TestDataset, self).__init__()\n",
        "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5HD3WHPtGwV"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82UAfnwSUgc_"
      },
      "source": [
        "### 2.2 Define a Segmenatation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEIkCqdfYnIn"
      },
      "source": [
        "You will need to define your CNN model for segmentation below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W6532hFXa_g"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )   \n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_pre = double_conv(1,3)       \n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512) \n",
        "       # self.dconv_down5 = double_conv(512, 1024)       \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        convpre = self.dconv_pre(x) #not maxpooling here\n",
        "        conv1 = self.dconv_down1(convpre)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        x = self.dconv_down4(x)\n",
        "        \n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        \n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1)   \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class CNNSEG(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=4):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(1, 3)\n",
        "        self.dconv_down2 = double_conv(3, 64)\n",
        "        self.dconv_down3 = double_conv(64, 128)\n",
        "        self.dconv_down4 = double_conv(128, 256)\n",
        "        self.dconv_down5 = double_conv(256, 512)          \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2) #kernel size two..stride = none\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        \n",
        "       # self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        #self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        #self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        self.dconv_up4 = double_conv(512+512, 512)\n",
        "        self.dconv_up3 = double_conv()\n",
        "        self.dconv_up2 = double_conv(512+512, 512)\n",
        "        self.dconv_up1 = double_conv(512+512, 512)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        conv4 = self.dconv_down4(x)\n",
        "        x = self.maxpool(conv4) \n",
        "\n",
        "        conv5 = self.dconv_down5(x)\n",
        "\n",
        "        x = self.upsample(conv5)        #left with 512 channels and ..becomes 12 * 12\n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "        \n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)   \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "#https://github.com/usuyama/pytorch-unet/blob/master/pytorch_unet.py\n",
        "\n",
        "model = UNet() # We can now create a model using your defined segmentation model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8JgA8I1VxIJ",
        "outputId": "66f2fc9c-87fb-49c1-ec87-a6032d5a6e00"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (dconv_pre): Sequential(\n",
              "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_down1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_down2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_down3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_down4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "  (dconv_up3): Sequential(\n",
              "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_up2): Sequential(\n",
              "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (dconv_up1): Sequential(\n",
              "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv_last): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXfeO8wDWV6S",
        "outputId": "2082e966-278c-44e9-9798-62cd34225a07"
      },
      "source": [
        "from torchsummary import  summary\n",
        "#help to view the visualisation of the model\n",
        "\n",
        "summary(model,input_size=(1,96,96))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 3, 96, 96]              30\n",
            "              ReLU-2            [-1, 3, 96, 96]               0\n",
            "            Conv2d-3            [-1, 3, 96, 96]              84\n",
            "              ReLU-4            [-1, 3, 96, 96]               0\n",
            "            Conv2d-5           [-1, 64, 96, 96]           1,792\n",
            "              ReLU-6           [-1, 64, 96, 96]               0\n",
            "            Conv2d-7           [-1, 64, 96, 96]          36,928\n",
            "              ReLU-8           [-1, 64, 96, 96]               0\n",
            "         MaxPool2d-9           [-1, 64, 48, 48]               0\n",
            "           Conv2d-10          [-1, 128, 48, 48]          73,856\n",
            "             ReLU-11          [-1, 128, 48, 48]               0\n",
            "           Conv2d-12          [-1, 128, 48, 48]         147,584\n",
            "             ReLU-13          [-1, 128, 48, 48]               0\n",
            "        MaxPool2d-14          [-1, 128, 24, 24]               0\n",
            "           Conv2d-15          [-1, 256, 24, 24]         295,168\n",
            "             ReLU-16          [-1, 256, 24, 24]               0\n",
            "           Conv2d-17          [-1, 256, 24, 24]         590,080\n",
            "             ReLU-18          [-1, 256, 24, 24]               0\n",
            "        MaxPool2d-19          [-1, 256, 12, 12]               0\n",
            "           Conv2d-20          [-1, 512, 12, 12]       1,180,160\n",
            "             ReLU-21          [-1, 512, 12, 12]               0\n",
            "           Conv2d-22          [-1, 512, 12, 12]       2,359,808\n",
            "             ReLU-23          [-1, 512, 12, 12]               0\n",
            "         Upsample-24          [-1, 512, 24, 24]               0\n",
            "           Conv2d-25          [-1, 256, 24, 24]       1,769,728\n",
            "             ReLU-26          [-1, 256, 24, 24]               0\n",
            "           Conv2d-27          [-1, 256, 24, 24]         590,080\n",
            "             ReLU-28          [-1, 256, 24, 24]               0\n",
            "         Upsample-29          [-1, 256, 48, 48]               0\n",
            "           Conv2d-30          [-1, 128, 48, 48]         442,496\n",
            "             ReLU-31          [-1, 128, 48, 48]               0\n",
            "           Conv2d-32          [-1, 128, 48, 48]         147,584\n",
            "             ReLU-33          [-1, 128, 48, 48]               0\n",
            "         Upsample-34          [-1, 128, 96, 96]               0\n",
            "           Conv2d-35           [-1, 64, 96, 96]         110,656\n",
            "             ReLU-36           [-1, 64, 96, 96]               0\n",
            "           Conv2d-37           [-1, 64, 96, 96]          36,928\n",
            "             ReLU-38           [-1, 64, 96, 96]               0\n",
            "           Conv2d-39            [-1, 4, 96, 96]             260\n",
            "================================================================\n",
            "Total params: 7,783,222\n",
            "Trainable params: 7,783,222\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 84.09\n",
            "Params size (MB): 29.69\n",
            "Estimated Total Size (MB): 113.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRdPFTa9a34J"
      },
      "source": [
        "### 2.3 Define a Loss function and optimizer\n",
        "\n",
        "You will need to define a loss function and an optimizer. torch.nn has a variety of readymade loss functions, although you may wish to create your own instead. torch.optim has a variety of optimizers, it is advised that you use one of these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRjOZGXRbUFT"
      },
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\"\"\"\n",
        "def dice_loss(pred,target, smooth = 1.):\n",
        "\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "    \"\"\"\n",
        "    When you call contiguous(), it actually makes a copy of the tensor such that the order of its elements in memory is the same as if it had been created from scratch with the same data.\n",
        "\n",
        "    Normally you don't need to worry about this. You're generally safe to assume everything will work, and wait until you get a RuntimeError: input is not contiguous where PyTorch expects a contiguous tensor to add a call to contiguous().\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# so we have two types of loss the dice loss and cross entropy loss\n",
        "\n",
        "def optimizer():\n",
        "  return optim.Adam(filter( lambda p:p.requires_grad,model.parameters()),lr=1e-4)\n",
        "\n",
        "optimizer_ft = optimizer()\n",
        "def exp_lr_scheduler():\n",
        "  return lr_scheduler.StepLR(optimizer_ft,step_size=30,gamma=0.1)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grDz3fR1qW_V"
      },
      "source": [
        "### 2.4 Training\n",
        "\n",
        "As most of you will use CPUs to train the model, expect your models to take **30 minutes to train if not longer depending on network architecture**. To save time, you should not be using all training data until your model is well developed. If you are running your model on a GPU training should be significantly faster. During the training process, you may want to save the checkpoints as follows:\n",
        "\n",
        "```\n",
        "# Saving checkpoints for validation/testing\n",
        "torch.save(model.state_dict(), path)\n",
        "```\n",
        "The saved checkpoints can be used to load at a later date for validation and testing. Here we give some example code for training a model. Note that you need to specify the max iterations you want to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrFNs1t6PjNR"
      },
      "source": [
        "# https://github.com/milesial/Pytorch-UNet/blob/master/utils/dice_score.py\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
        "    # Average of Dice coefficient for all batches, or for a single mask\n",
        "    assert input.size() == target.size()\n",
        "    if input.dim() == 2 and reduce_batch_first:\n",
        "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')\n",
        "\n",
        "    if input.dim() == 2 or reduce_batch_first:\n",
        "        inter = torch.dot(input.reshape(-1), target.reshape(-1))\n",
        "        sets_sum = torch.sum(input) + torch.sum(target)\n",
        "        if sets_sum.item() == 0:\n",
        "            sets_sum = 2 * inter\n",
        "\n",
        "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
        "    else:\n",
        "        # compute and average metric for each batch element\n",
        "        dice = 0\n",
        "        for i in range(input.shape[0]):\n",
        "            dice += dice_coeff(input[i, ...], target[i, ...])\n",
        "        return dice / input.shape[0]\n",
        "\n",
        "\n",
        "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
        "    # Average of Dice coefficient for all classes\n",
        "    assert input.size() == target.size()\n",
        "    dice = 0\n",
        "    for channel in range(input.shape[1]):\n",
        "        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
        "\n",
        "    return dice / input.shape[1]\n",
        "\n",
        "\n",
        "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
        "    # Dice loss (objective to minimize) between 0 and 1\n",
        "    assert input.size() == target.size()\n",
        "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
        "    return 1 - fn(input, target, reduce_batch_first=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCb4bxVVchxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7fcc0a-5ebe-402b-d507-cf744de5cd6c"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\"\"\"\n",
        "def print_metrics(metrics, epoch_samples, phase='train'):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def calc_loss(pred,target,metrics,bce_weight=0.5) :\n",
        "    #bce = F.binary_cross_entropy_with_logits(pred,target)\n",
        "\n",
        "    pred = torch.sigmoid(pred)\n",
        "    dice = dice_loss(pred,target) \n",
        "\n",
        "    #loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "    \n",
        "\n",
        "    metrics['bce'] += 1#bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += 1#loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return metrics['loss']\n",
        "\"\"\"\n",
        "checkpoint_path = \"checkpoint.pth\"\n",
        "data_path = '/content/drive/MyDrive/data/train/'\n",
        "num_workers = 4\n",
        "batch_size = 4\n",
        "\"\"\"\n",
        "#what does data loader do?\n",
        "Dataset stores the samples and their corresponding labels, and \n",
        "DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def train_net(model,\n",
        "              device,\n",
        "              epochs: int =5,\n",
        "              batch_size: int = 1,\n",
        "              learning_rate: float = 0.001,\n",
        "              #val_percent: float = 0.1,\n",
        "              #save_checkpoint: bool = True,\n",
        "             # img_scale: float = 0.5,\n",
        "              amp: bool = False\n",
        "):\n",
        "#print(\"training the network...\")\n",
        "# Fetch images and labels.\n",
        "  model.train()  #funciton of the module superclass ..sets the model to train.\n",
        "  train_set = TrainDataset(data_path)\n",
        "  training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, shuffle=True)\n",
        " # https://github.com/milesial/Pytorch-UNet/blob/master/train.py \n",
        "\n",
        "  optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
        "  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  if isinstance(criterion,torch.nn.Module): ##just to be sure that criterion is on the correct device.\n",
        "    criterion.to(device)\n",
        "  global_step = 0\n",
        "\n",
        "\n",
        "  for epoch in range(epochs) :\n",
        "    #torch.set_grad_enabled(True)\n",
        "    epoch_samples = 0\n",
        "    epoch_loss=0\n",
        "    metrics = defaultdict(float)\n",
        "    since = time.time()\n",
        "    with tqdm(len(train_set), desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:     \n",
        "      for iteration, sample in enumerate(training_data_loader):\n",
        "          img, mask = sample\n",
        "          img=img.unsqueeze(0)\n",
        "          img  = img.to(device = device)\n",
        "          mask = mask.squeeze(1)\n",
        "          mask = mask.to(device,dtype = torch.long)\n",
        "\n",
        "      \n",
        "          #mask = F.one_hot(mask,4).permute(0,3,1,2).float()\n",
        "          print(mask.shape)\n",
        "          \"\"\"\n",
        "          torch.cuda.amp and torch provide convenience methods for mixed precision,\n",
        "          where some operations use the torch.float32 (float) datatype and other operations use torch.float16 (half).\n",
        "          Some ops, like linear layers and convolutions, are much faster in float16. \n",
        "          Other ops, like reductions, often require the dynamic range of float32. \n",
        "          Mixed precision tries to match each op to its appropriate datatype.\n",
        "          \"\"\"\n",
        "          #with torch.cuda.amp.autocast(enabled = amp)\n",
        "          out  = model(img)\n",
        "          print(out.shape)\n",
        "          loss = criterion (out,mask) # +dice_loss(F.softmax(out,dim=1).float(),\n",
        "                                                  #mask,multiclass = True)\n",
        "    \n",
        "    # Then write your BACKWARD & OPTIMIZE below\n",
        "    # Note: Compute Loss and Optimize\n",
        "    #loss = criterion(out,mask)\n",
        "    #loss_value = loss.item()\n",
        "    #train_losses.append(loss_value)\n",
        "    #loss.backward()\n",
        "          optimizer.zero_grad(set_to_none=True)\n",
        "          grad_scaler.scale(loss).backward()\n",
        "          grad_scaler.step(optimizer)\n",
        "          grad_scaler.update()\n",
        "\n",
        "          pbar.update(img.shape[0])\n",
        "          global_step += 1\n",
        "          epoch_loss += loss.item()\n",
        "          #experiment.log({\n",
        "           #         'train loss': loss.item(),\n",
        "            #        'step': global_step,\n",
        "             #       'epoch': epoch\n",
        "               # })\n",
        "          print('train loss',loss.item(),' step :',global_step,' epoch :',epoch)\n",
        "          pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "train_net(model,device)\n",
        "\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch 1/5: 3img [00:00, 11.21img/s, loss (batch)=0.695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6438510417938232  step : 1  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6946656703948975  step : 2  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 6img [00:00, 12.56img/s, loss (batch)=0.772]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5968152284622192  step : 3  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.49230507016181946  step : 4  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9694870710372925  step : 5  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7720135450363159  step : 6  epoch : 0\n",
            "torch.Size([1, 96, 96])"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 9img [00:00, 14.58img/s, loss (batch)=0.603]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0201952457427979  step : 7  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5857422947883606  step : 8  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6029329895973206  step : 9  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 13img [00:00, 16.46img/s, loss (batch)=0.422]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.591218888759613  step : 10  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.545095682144165  step : 11  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9291982650756836  step : 12  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.42232707142829895  step : 13  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 17img [00:01, 16.85img/s, loss (batch)=0.491]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6891436576843262  step : 14  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5934986472129822  step : 15  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6967999339103699  step : 16  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.49143123626708984  step : 17  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 21img [00:01, 17.46img/s, loss (batch)=0.809]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.162735939025879  step : 18  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.785862386226654  step : 19  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8109195232391357  step : 20  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8093310594558716  step : 21  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 25img [00:01, 17.88img/s, loss (batch)=0.981]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.33611661195755005  step : 22  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4491441547870636  step : 23  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9313198924064636  step : 24  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9805493950843811  step : 25  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 29img [00:01, 17.81img/s, loss (batch)=0.588]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7280109524726868  step : 26  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7078601121902466  step : 27  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5711801052093506  step : 28  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5875945687294006  step : 29  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 33img [00:02, 17.23img/s, loss (batch)=0.818]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6905625462532043  step : 30  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5349653959274292  step : 31  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.693942129611969  step : 32  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.817760169506073  step : 33  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 37img [00:02, 17.33img/s, loss (batch)=0.673]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5982047319412231  step : 34  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6464424729347229  step : 35  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.46406787633895874  step : 36  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6732566356658936  step : 37  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 41img [00:02, 17.31img/s, loss (batch)=0.556]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6210591793060303  step : 38  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8654193878173828  step : 39  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7951979637145996  step : 40  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5561647415161133  step : 41  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 45img [00:02, 17.20img/s, loss (batch)=0.728]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7636830806732178  step : 42  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6609619855880737  step : 43  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7654738426208496  step : 44  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7279043793678284  step : 45  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 50img [00:02, 18.10img/s, loss (batch)=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6535052061080933  step : 46  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5667465925216675  step : 47  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8924737572669983  step : 48  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6687536239624023  step : 49  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 53img [00:03, 17.78img/s, loss (batch)=1.06] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6330052614212036  step : 50  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.723712682723999  step : 51  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6216680407524109  step : 52  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0622992515563965  step : 53  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 57img [00:03, 17.85img/s, loss (batch)=0.595]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4335496425628662  step : 54  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5817344188690186  step : 55  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5359121561050415  step : 56  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5951426029205322  step : 57  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 61img [00:03, 18.74img/s, loss (batch)=0.629]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5475419163703918  step : 58  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.44578394293785095  step : 59  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6947718858718872  step : 60  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6293408870697021  step : 61  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 65img [00:03, 18.02img/s, loss (batch)=0.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9741518497467041  step : 62  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6498897075653076  step : 63  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8500198721885681  step : 64  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.43003731966018677  step : 65  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 69img [00:04, 17.95img/s, loss (batch)=0.714]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5684306025505066  step : 66  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5869418382644653  step : 67  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9464322328567505  step : 68  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7139907479286194  step : 69  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 73img [00:04, 17.47img/s, loss (batch)=0.628]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7345209121704102  step : 70  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7823855876922607  step : 71  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.662030041217804  step : 72  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6279581785202026  step : 73  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 77img [00:04, 18.13img/s, loss (batch)=0.611]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7081284523010254  step : 74  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5799310803413391  step : 75  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4878925085067749  step : 76  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6112760305404663  step : 77  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 81img [00:04, 17.83img/s, loss (batch)=0.515]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7195420265197754  step : 78  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.45512309670448303  step : 79  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5349054336547852  step : 80  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5151792168617249  step : 81  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 85img [00:04, 17.87img/s, loss (batch)=0.703]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6813637614250183  step : 82  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6102191209793091  step : 83  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.604044497013092  step : 84  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7033961415290833  step : 85  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 89img [00:05, 17.95img/s, loss (batch)=0.362]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7172872424125671  step : 86  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7633435726165771  step : 87  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7650877833366394  step : 88  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.3622044324874878  step : 89  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 93img [00:05, 18.09img/s, loss (batch)=0.814]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6416741013526917  step : 90  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6471021175384521  step : 91  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6793063282966614  step : 92  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8141579627990723  step : 93  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 97img [00:05, 18.71img/s, loss (batch)=0.447]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6257504224777222  step : 94  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6469707489013672  step : 95  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5130510330200195  step : 96  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.44678995013237  step : 97  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100img [00:05, 17.10img/s, loss (batch)=0.681]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.42143571376800537  step : 98  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.76920086145401  step : 99  epoch : 0\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6811964511871338  step : 100  epoch : 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 4img [00:00, 13.51img/s, loss (batch)=0.412]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.1151458024978638  step : 101  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6932019591331482  step : 102  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.41160038113594055  step : 103  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 8img [00:00, 16.79img/s, loss (batch)=0.515]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.764289915561676  step : 104  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5197246074676514  step : 105  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4394211769104004  step : 106  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5148603916168213  step : 107  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 12img [00:00, 17.39img/s, loss (batch)=0.797]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.47776952385902405  step : 108  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6570472717285156  step : 109  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9264455437660217  step : 110  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7966711521148682  step : 111  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 16img [00:00, 17.70img/s, loss (batch)=0.585]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.630813717842102  step : 112  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5952606201171875  step : 113  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.1011905670166016  step : 114  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.585123598575592  step : 115  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 20img [00:01, 17.91img/s, loss (batch)=0.623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6579980850219727  step : 116  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.47703632712364197  step : 117  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5418261885643005  step : 118  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6228418946266174  step : 119  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 24img [00:01, 17.81img/s, loss (batch)=0.555]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7065775990486145  step : 120  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9260182976722717  step : 121  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6731253862380981  step : 122  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5545694231987  step : 123  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 28img [00:01, 17.84img/s, loss (batch)=0.691]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7011877298355103  step : 124  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5781654715538025  step : 125  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6013159155845642  step : 126  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.690663754940033  step : 127  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 32img [00:01, 17.96img/s, loss (batch)=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.3498602509498596  step : 128  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.45974573493003845  step : 129  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8286783695220947  step : 130  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6679575443267822  step : 131  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 35img [00:02, 17.63img/s, loss (batch)=0.707]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7272307872772217  step : 132  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9478736519813538  step : 133  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8449164032936096  step : 134  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7072376608848572  step : 135  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 40img [00:02, 17.75img/s, loss (batch)=0.433]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5572407841682434  step : 136  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6871941089630127  step : 137  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9102767109870911  step : 138  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.43282270431518555  step : 139  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 44img [00:02, 18.09img/s, loss (batch)=0.635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4777947664260864  step : 140  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5050100684165955  step : 141  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5492743253707886  step : 142  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6351413726806641  step : 143  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 48img [00:02, 18.08img/s, loss (batch)=0.567]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9721076488494873  step : 144  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4232288599014282  step : 145  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.665012776851654  step : 146  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5673664212226868  step : 147  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 51img [00:02, 17.81img/s, loss (batch)=0.687]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4405132830142975  step : 148  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7374024391174316  step : 149  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7830955982208252  step : 150  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6871940493583679  step : 151  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 56img [00:03, 18.28img/s, loss (batch)=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7118975520133972  step : 152  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5850857496261597  step : 153  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5503928065299988  step : 154  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0048229694366455  step : 155  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 60img [00:03, 18.07img/s, loss (batch)=1.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.82277911901474  step : 156  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7288563251495361  step : 157  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.564124345779419  step : 158  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.018275260925293  step : 159  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 64img [00:03, 18.07img/s, loss (batch)=0.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.39059653878211975  step : 160  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6420031785964966  step : 161  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5893640518188477  step : 162  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5996523499488831  step : 163  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 68img [00:03, 18.02img/s, loss (batch)=0.617]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.643677294254303  step : 164  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7513494491577148  step : 165  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7118046879768372  step : 166  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6172485947608948  step : 167  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 71img [00:04, 17.24img/s, loss (batch)=0.645]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6037414073944092  step : 168  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5239608287811279  step : 169  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6567661166191101  step : 170  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6454194188117981  step : 171  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 75img [00:04, 17.67img/s, loss (batch)=0.456]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9114606380462646  step : 172  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7890447974205017  step : 173  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5296298265457153  step : 174  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.455609530210495  step : 175  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 80img [00:04, 17.93img/s, loss (batch)=0.668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7761415839195251  step : 176  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6899056434631348  step : 177  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5807075500488281  step : 178  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6678842902183533  step : 179  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 83img [00:04, 17.71img/s, loss (batch)=0.829]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5587568283081055  step : 180  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7121932506561279  step : 181  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7712461948394775  step : 182  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8290226459503174  step : 183  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 87img [00:04, 17.72img/s, loss (batch)=0.586]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7288993000984192  step : 184  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7750042676925659  step : 185  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7629778981208801  step : 186  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.586230993270874  step : 187  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 92img [00:05, 17.80img/s, loss (batch)=0.645]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.41076457500457764  step : 188  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7494474053382874  step : 189  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6119992733001709  step : 190  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6454344391822815  step : 191  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 96img [00:05, 18.50img/s, loss (batch)=0.622]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.681948721408844  step : 192  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.750867486000061  step : 193  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6869090795516968  step : 194  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6221928000450134  step : 195  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100img [00:05, 18.67img/s, loss (batch)=0.518]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6054723262786865  step : 196  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6124274730682373  step : 197  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6439778804779053  step : 198  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7131227850914001  step : 199  epoch : 1\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5181896686553955  step : 200  epoch : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100img [00:05, 17.41img/s, loss (batch)=0.518]\n",
            "Epoch 3/5: 4img [00:00, 13.97img/s, loss (batch)=0.705]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7925395369529724  step : 201  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8227136135101318  step : 202  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7053295969963074  step : 203  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 8img [00:00, 16.14img/s, loss (batch)=0.642]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6113808155059814  step : 204  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.021154522895813  step : 205  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5660864114761353  step : 206  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6424806118011475  step : 207  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 12img [00:00, 17.14img/s, loss (batch)=0.731]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5578098297119141  step : 208  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.42326095700263977  step : 209  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.587708592414856  step : 210  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7305965423583984  step : 211  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 15img [00:00, 18.11img/s, loss (batch)=0.708]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.668737530708313  step : 212  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6279212236404419  step : 213  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5276517868041992  step : 214  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7076507210731506  step : 215  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 19img [00:01, 17.96img/s, loss (batch)=0.954]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5570912957191467  step : 216  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.37551212310791016  step : 217  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.41308653354644775  step : 218  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.95401531457901  step : 219  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 23img [00:01, 18.06img/s, loss (batch)=0.954]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7779411673545837  step : 220  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.779683530330658  step : 221  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7893550992012024  step : 222  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9543484449386597  step : 223  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 27img [00:01, 18.27img/s, loss (batch)=0.835]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6911605000495911  step : 224  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7264077067375183  step : 225  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9197052717208862  step : 226  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8353418707847595  step : 227  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 31img [00:01, 18.22img/s, loss (batch)=0.605]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.531235933303833  step : 228  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0606646537780762  step : 229  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.749299168586731  step : 230  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6050974726676941  step : 231  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 35img [00:02, 17.48img/s, loss (batch)=0.676]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4956530034542084  step : 232  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6370257139205933  step : 233  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6190760135650635  step : 234  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6762588024139404  step : 235  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 39img [00:02, 18.03img/s, loss (batch)=0.523]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7069981694221497  step : 236  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5050733685493469  step : 237  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6412135362625122  step : 238  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5231256484985352  step : 239  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 43img [00:02, 18.01img/s, loss (batch)=0.914]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6951574087142944  step : 240  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7957872748374939  step : 241  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.729129433631897  step : 242  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9140906929969788  step : 243  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 47img [00:02, 17.89img/s, loss (batch)=0.785]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5920207500457764  step : 244  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5687413811683655  step : 245  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5751360058784485  step : 246  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7848541736602783  step : 247  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 51img [00:02, 17.81img/s, loss (batch)=0.431]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.41444212198257446  step : 248  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4595828652381897  step : 249  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9846094846725464  step : 250  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4305514097213745  step : 251  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 55img [00:03, 17.10img/s, loss (batch)=0.715]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7222954630851746  step : 252  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.3834957182407379  step : 253  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7314567565917969  step : 254  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7151170372962952  step : 255  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 60img [00:03, 17.90img/s, loss (batch)=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.3113870322704315  step : 256  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8300029635429382  step : 257  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5106085538864136  step : 258  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.012397289276123  step : 259  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 63img [00:03, 18.09img/s, loss (batch)=0.581]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5065863132476807  step : 260  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5254505276679993  step : 261  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7635442018508911  step : 262  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5814633965492249  step : 263  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 68img [00:03, 17.77img/s, loss (batch)=0.542]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5775026679039001  step : 264  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9245198369026184  step : 265  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6159178614616394  step : 266  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5421882271766663  step : 267  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 71img [00:04, 17.55img/s, loss (batch)=0.656]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5761001110076904  step : 268  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6490528583526611  step : 269  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5589170455932617  step : 270  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6556313037872314  step : 271  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 75img [00:04, 17.64img/s, loss (batch)=0.701]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.63556307554245  step : 272  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6518159508705139  step : 273  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4727591276168823  step : 274  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7014252543449402  step : 275  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 80img [00:04, 17.77img/s, loss (batch)=0.669]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6373922824859619  step : 276  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7389299869537354  step : 277  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.45421159267425537  step : 278  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6693013906478882  step : 279  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 84img [00:04, 18.18img/s, loss (batch)=0.841]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6500949859619141  step : 280  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.43342316150665283  step : 281  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6876429915428162  step : 282  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8405061364173889  step : 283  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 88img [00:04, 18.27img/s, loss (batch)=0.687]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6746760606765747  step : 284  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.646827220916748  step : 285  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7492302656173706  step : 286  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6869710683822632  step : 287  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 92img [00:05, 18.64img/s, loss (batch)=0.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5070860981941223  step : 288  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6148415207862854  step : 289  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7704858779907227  step : 290  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6904911398887634  step : 291  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 96img [00:05, 18.75img/s, loss (batch)=0.601]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6168171763420105  step : 292  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5338858962059021  step : 293  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7690823674201965  step : 294  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6009988188743591  step : 295  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 99img [00:05, 18.44img/s, loss (batch)=0.725]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.090423345565796  step : 296  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6921937465667725  step : 297  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6040516495704651  step : 298  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7247669696807861  step : 299  epoch : 2\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100img [00:05, 17.44img/s, loss (batch)=0.594]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5941804647445679  step : 300  epoch : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 4img [00:00, 13.47img/s, loss (batch)=0.701]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6467037796974182  step : 301  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.653503954410553  step : 302  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7012274861335754  step : 303  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 8img [00:00, 16.90img/s, loss (batch)=0.718]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5869089961051941  step : 304  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9028087258338928  step : 305  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5706942081451416  step : 306  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7175732851028442  step : 307  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 11img [00:00, 17.04img/s, loss (batch)=1.09] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9228506088256836  step : 308  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6172279715538025  step : 309  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5345675945281982  step : 310  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0857058763504028  step : 311  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 15img [00:00, 18.41img/s, loss (batch)=0.761]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6068087816238403  step : 312  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6238263249397278  step : 313  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6123243570327759  step : 314  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7605526447296143  step : 315  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 19img [00:01, 18.14img/s, loss (batch)=0.566]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7118103504180908  step : 316  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6704169511795044  step : 317  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.674505352973938  step : 318  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5664889812469482  step : 319  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 23img [00:01, 17.45img/s, loss (batch)=0.598]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5334361791610718  step : 320  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7673743963241577  step : 321  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.44325026869773865  step : 322  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5984205007553101  step : 323  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 27img [00:01, 18.28img/s, loss (batch)=0.711]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.44930893182754517  step : 324  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5925124883651733  step : 325  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4570145010948181  step : 326  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7109130024909973  step : 327  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 31img [00:01, 18.40img/s, loss (batch)=0.404]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.57343989610672  step : 328  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6995823383331299  step : 329  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.3601967692375183  step : 330  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.40390801429748535  step : 331  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 35img [00:02, 17.85img/s, loss (batch)=0.302]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6785990595817566  step : 332  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5123958587646484  step : 333  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5007174015045166  step : 334  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.3020712435245514  step : 335  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 39img [00:02, 18.58img/s, loss (batch)=0.825]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8187071681022644  step : 336  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.711190938949585  step : 337  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4546775817871094  step : 338  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8253804445266724  step : 339  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 43img [00:02, 18.33img/s, loss (batch)=0.696]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4045131504535675  step : 340  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.1589078903198242  step : 341  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8058866858482361  step : 342  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6955090761184692  step : 343  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 47img [00:02, 17.49img/s, loss (batch)=0.49] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9632197618484497  step : 344  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5879635810852051  step : 345  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6269777417182922  step : 346  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.48975732922554016  step : 347  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 51img [00:02, 18.00img/s, loss (batch)=0.674]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9541712999343872  step : 348  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8181287050247192  step : 349  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7414654493331909  step : 350  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6744563579559326  step : 351  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 55img [00:03, 18.26img/s, loss (batch)=0.69] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5901658535003662  step : 352  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.726599395275116  step : 353  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6805631518363953  step : 354  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6903120875358582  step : 355  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 59img [00:03, 18.11img/s, loss (batch)=0.639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5459611415863037  step : 356  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7321622371673584  step : 357  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6967552304267883  step : 358  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6390032768249512  step : 359  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 63img [00:03, 18.14img/s, loss (batch)=1.51]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.908659815788269  step : 360  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5870689749717712  step : 361  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0947884321212769  step : 362  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.5113645792007446  step : 363  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 67img [00:03, 18.03img/s, loss (batch)=0.574]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.014549970626831  step : 364  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7261248826980591  step : 365  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4619736671447754  step : 366  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5741860866546631  step : 367  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 71img [00:04, 17.84img/s, loss (batch)=0.851]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.39368247985839844  step : 368  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9466722011566162  step : 369  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.680314302444458  step : 370  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8513364195823669  step : 371  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 75img [00:04, 17.51img/s, loss (batch)=0.89] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8436269760131836  step : 372  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9238436818122864  step : 373  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.644810676574707  step : 374  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.890099823474884  step : 375  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 79img [00:04, 17.31img/s, loss (batch)=1.04] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9698988795280457  step : 376  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.988586962223053  step : 377  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9547801613807678  step : 378  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.035322666168213  step : 379  epoch : 3\n",
            "torch.Size([1, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 83img [00:04, 17.00img/s, loss (batch)=0.994]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7072311043739319  step : 380  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0506757497787476  step : 381  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9941064119338989  step : 382  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.766552209854126  step : 383  epoch : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 87img [00:04, 17.11img/s, loss (batch)=0.416]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7688314318656921  step : 384  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5446910262107849  step : 385  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4159322679042816  step : 386  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 90img [00:05, 17.31img/s, loss (batch)=0.852]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.0600037574768066  step : 387  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.810700535774231  step : 388  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8634594678878784  step : 389  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8519453406333923  step : 390  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 95img [00:05, 17.68img/s, loss (batch)=0.727]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6942043900489807  step : 391  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.712177038192749  step : 392  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9419975280761719  step : 393  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7274805903434753  step : 394  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 99img [00:05, 18.42img/s, loss (batch)=0.527]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5785682201385498  step : 395  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7269585132598877  step : 396  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6502510905265808  step : 397  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5271408557891846  step : 398  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100img [00:05, 17.29img/s, loss (batch)=0.664]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7202596664428711  step : 399  epoch : 3\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6636773347854614  step : 400  epoch : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 3img [00:00, 12.27img/s, loss (batch)=0.558]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7773511409759521  step : 401  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5298402309417725  step : 402  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5580921173095703  step : 403  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 7img [00:00, 16.26img/s, loss (batch)=0.716]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8844360113143921  step : 404  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8138084411621094  step : 405  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7447802424430847  step : 406  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7156400680541992  step : 407  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 11img [00:00, 16.69img/s, loss (batch)=0.651]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9391549229621887  step : 408  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6733803749084473  step : 409  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6484547853469849  step : 410  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6509281992912292  step : 411  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 15img [00:00, 17.35img/s, loss (batch)=0.78] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6093398928642273  step : 412  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5745619535446167  step : 413  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6219817399978638  step : 414  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7799108028411865  step : 415  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 19img [00:01, 17.65img/s, loss (batch)=0.511]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7512611746788025  step : 416  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7169779539108276  step : 417  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4310930669307709  step : 418  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5108281373977661  step : 419  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 23img [00:01, 18.22img/s, loss (batch)=1.07] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.46383535861968994  step : 420  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.45782968401908875  step : 421  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7358335852622986  step : 422  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0679051876068115  step : 423  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 27img [00:01, 18.58img/s, loss (batch)=0.754]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6532850861549377  step : 424  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7363205552101135  step : 425  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9284335374832153  step : 426  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7544572353363037  step : 427  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 31img [00:01, 18.15img/s, loss (batch)=0.397]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4698801636695862  step : 428  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7048092484474182  step : 429  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6585182547569275  step : 430  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.39671456813812256  step : 431  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 35img [00:02, 17.55img/s, loss (batch)=0.693]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6416807174682617  step : 432  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.3901745080947876  step : 433  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5505506992340088  step : 434  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6934038996696472  step : 435  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 39img [00:02, 17.59img/s, loss (batch)=0.708]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7248024940490723  step : 436  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7586419582366943  step : 437  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7269956469535828  step : 438  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7077383399009705  step : 439  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 43img [00:02, 18.38img/s, loss (batch)=0.564]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7218592762947083  step : 440  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6643608212471008  step : 441  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7089627385139465  step : 442  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.564433217048645  step : 443  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 47img [00:02, 18.54img/s, loss (batch)=0.711]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5622143149375916  step : 444  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5536239147186279  step : 445  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6352813243865967  step : 446  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7111790776252747  step : 447  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 51img [00:02, 18.41img/s, loss (batch)=0.636]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6263488531112671  step : 448  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5180514454841614  step : 449  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5919890403747559  step : 450  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6357667446136475  step : 451  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 55img [00:03, 17.76img/s, loss (batch)=0.579]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.4121493697166443  step : 452  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8668404817581177  step : 453  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5798028111457825  step : 454  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5790782570838928  step : 455  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 59img [00:03, 18.02img/s, loss (batch)=0.753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5296903252601624  step : 456  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5145256519317627  step : 457  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6491400003433228  step : 458  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7531185746192932  step : 459  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 63img [00:03, 17.92img/s, loss (batch)=0.465]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.5783160328865051  step : 460  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5991001129150391  step : 461  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 1.0594719648361206  step : 462  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.46458113193511963  step : 463  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 67img [00:03, 17.92img/s, loss (batch)=0.747]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8866493105888367  step : 464  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6057164669036865  step : 465  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4782455265522003  step : 466  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7474954128265381  step : 467  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 71img [00:04, 17.95img/s, loss (batch)=0.584]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6800188422203064  step : 468  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9305846095085144  step : 469  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5327770113945007  step : 470  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5837606191635132  step : 471  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 75img [00:04, 17.75img/s, loss (batch)=0.658]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.9943773746490479  step : 472  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7600017189979553  step : 473  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.563835859298706  step : 474  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6576111912727356  step : 475  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 79img [00:04, 17.84img/s, loss (batch)=0.449]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7932460904121399  step : 476  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.769865095615387  step : 477  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7398115992546082  step : 478  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.4488793611526489  step : 479  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 83img [00:04, 17.79img/s, loss (batch)=0.91] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8285146355628967  step : 480  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6618466973304749  step : 481  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6782601475715637  step : 482  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9102939963340759  step : 483  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 87img [00:04, 17.74img/s, loss (batch)=0.574]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6963851451873779  step : 484  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6939334273338318  step : 485  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5977579951286316  step : 486  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.5743594169616699  step : 487  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 91img [00:05, 18.09img/s, loss (batch)=0.787]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.8274158239364624  step : 488  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.70320725440979  step : 489  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7030025720596313  step : 490  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7870851159095764  step : 491  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 95img [00:05, 18.46img/s, loss (batch)=0.764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.7801429033279419  step : 492  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.9169502258300781  step : 493  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7231762409210205  step : 494  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.7642805576324463  step : 495  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 99img [00:05, 18.34img/s, loss (batch)=0.658]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.0468775033950806  step : 496  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.8090575337409973  step : 497  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6354923248291016  step : 498  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n",
            "train loss 0.6583325266838074  step : 499  epoch : 4\n",
            "torch.Size([1, 96, 96])\n",
            "torch.Size([1, 4, 96, 96])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100img [00:05, 17.40img/s, loss (batch)=0.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6598200798034668  step : 500  epoch : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCZP-xof-Sst"
      },
      "source": [
        "### 2.5 Testing\n",
        "\n",
        "When validating the trained checkpoints (models), remember to change the model status as **Evaluation Mode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGmhTdkciDt0"
      },
      "source": [
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVS22lrjqW_V"
      },
      "source": [
        "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
        "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
        "data_path = './data/test'\n",
        "num_workers = 4\n",
        "batch_size = 2\n",
        "\n",
        "test_set = TestDataset(data_path)\n",
        "test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for iteration, sample in enumerate(test_data_loader):\n",
        "    img = sample\n",
        "    print(img.shape)\n",
        "\n",
        "    plt.imshow(img[0,...].squeeze(), cmap='gray') #visualise all images in test set\n",
        "    plt.pause(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsycVbIuUov3"
      },
      "source": [
        "## 3 Evaluation\n",
        "\n",
        "As we will automatically evaluate your predicted test makes on Kaggle, in this section we expect you to learn:\n",
        "* what is the Dice score used on Kaggle to measure your models performance\n",
        "* how to submit your predicted masks to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NicQyj47jsD1"
      },
      "source": [
        "### 3.1 Dice Score\n",
        "\n",
        "To evaluate the quality of the predicted masks, the Dice score is adopted. Dice score on two masks A and B is defined as the intersection ratio between the overlap area and the average area of two masks. A higher Dice suggests a better registration.\n",
        "\n",
        "$Dice (A, B)= \\frac{2|A \\cap B|}{|A| + |B|} $\n",
        "\n",
        "However, in our coursework, we have three labels in each mask, we will compute the Dice score for each label and then average the three of them as the final score. Below we have given you `categorical_dice` for free so you can test your results before submission to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzOY4GROqW_V"
      },
      "source": [
        "def categorical_dice(mask1, mask2, label_class=1):\n",
        "    \"\"\"\n",
        "    Dice score of a specified class between two volumes of label masks.\n",
        "    (classes are encoded but by label class number not one-hot )\n",
        "    Note: stacks of 2D slices are considered volumes.\n",
        "\n",
        "    Args:\n",
        "        mask1: N label masks, numpy array shaped (H, W, N)\n",
        "        mask2: N label masks, numpy array shaped (H, W, N)\n",
        "        label_class: the class over which to calculate dice scores\n",
        "\n",
        "    Returns:\n",
        "        volume_dice\n",
        "    \"\"\"\n",
        "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
        "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
        "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
        "    return dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZcsrwmVjy5k"
      },
      "source": [
        "### 3.2 Submission\n",
        "\n",
        "Kaggle requires your submission to be in a specific CSV format. To help ensure your submissions are in the correct format, we have provided some helper functions to do this for you. For those interested, the png images are run-length encoded and saved in a CSV to the specifications required by our competition.\n",
        "\n",
        "It is sufficient to use this helper function. To do so, save your 80 predicted masks into a directory. ONLY the 80 predicted masks should be in this directory. Call the submission_converter function with the first argument as the directory containing your masks, and the second the directory in which you wish to save your submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDVbgu0qW_V"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def rle_encoding(x):\n",
        "    '''\n",
        "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
        "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "    Returns run length as list\n",
        "    '''\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "\n",
        "def submission_converter(mask_directory, path_to_save):\n",
        "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
        "    writer.write('id,encoding\\n')\n",
        "\n",
        "    files = os.listdir(mask_directory)\n",
        "\n",
        "    for file in files:\n",
        "        name = file[:-4]\n",
        "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        mask1 = (mask == 1)\n",
        "        mask2 = (mask == 2)\n",
        "        mask3 = (mask == 3)\n",
        "\n",
        "        encoded_mask1 = rle_encoding(mask1)\n",
        "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
        "        encoded_mask2 = rle_encoding(mask2)\n",
        "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
        "        encoded_mask3 = rle_encoding(mask3)\n",
        "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
        "\n",
        "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
        "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
        "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
        "\n",
        "    writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bOn_j_FqW_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g_jvJUntGwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}